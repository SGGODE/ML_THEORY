Problem definition — What business problem are we trying to solve? How can it be phrased as a machine learning problem?
Data — If machine learning is getting insights out of data, what data we have? How does it match the problem definition? Is our data structured or unstructured? Static or streaming?
Evaluation — What defines success? Is a 95% accurate machine learning model good enough?
Features — What parts of our data are we going to use for our model? How can what we already know influence this?
Modelling — Which model should you choose? How can you improve it? How do you compare it with other models?
Experimentation — What else could we try? Does our deployed model do as we expected? How do the other steps change based on what we’ve found?
Let’s dive a little deeper in each.

1. Problem definition — Rephrase your business problem as a machine learning problem
To help decide whether or not your business could use machine learning, the first step is to match the business problem you’re 
trying to solve a machine learning problem.

The four major types of machine learning are supervised learning, unsupervised learning, transfer learning and reinforcement 
learning (there’s semi-supervised as well but I’ve left it out for brevity). The three most used in business applications are supervised learning, 
unsupervised learning and transfer learning.

Supervised learning
Supervised learning, is called supervised because you have data and labels. A machine learning algorithm tries to learn what patterns in the data 
lead to the labels. The supervised part happens during training. If the algorithm guesses a wrong label, it tries to correct itself.

For example, if you were trying to predict heart disease in a new patient. You may have the anonymised medical records of 100 patients as the data 
and whether or not they had heart disease as the label.

Unsupervised learning
Unsupervised learning is when you have data but no labels. The data could be the purchase history of your online video game store customers. 
Using this data, you may want to group similar customers together so you can offer them specialised deals. You could use a machine learning algorithm to 
group your customers by purchase history.

After inspecting the groups, you provide the labels. There may be a group interested in computer games, another group who prefer console games and 
another which only buy discounted older games. This is called clustering.

What’s important to remember here is the algorithm did not provide these labels. It found the patterns between similar customers and using your domain 
knowledge, you provided the labels.

Transfer learning
Transfer learning is when you take the information an existing machine learning model has learned and adjust it to your own problem.

Training a machine learning model from scratch can be expensive and time-consuming. The good news is, you don’t always have to. When machine learning 
algorithms find patterns in one kind of data, these patterns can be used in another type of data.

Let’s say you’re a car insurance company and wanted to build a text classification model to classify whether or not someone submitting an insurance claim 
for a car accident is at fault (caused the accident) or not at fault (didn’t cause the accident).

You could start with an existing text model, one which has read all of Wikipedia and has remembered all the patterns between different words, such as, which 
word is more likely to come next after another. Then using your car insurance claims (data) along with their outcomes (labels), you could tweak the existing text model to your own problem.

If machine learning can be used in your business, it’s likely it’ll fall under one of these three types of learning. But let’s break them down further into 
classification, regression and recommendation.

Classification — Do you want to predict whether something is one thing or another? Such as whether a customer will churn or not churn? Or whether a patient has 
heart disease or not? Note, there can be more than two things. Two classes is called binary classification, more than two classes is called multi-class classification. 
Multi-label is when an 
item can belong to more than one class.
Regression — Do you want to predict a specific number of something? Such as how much a house will sell for? Or how many customers will visit your site next month?
Recommendation — Do you want to recommend something to someone? Such as products to buy based on their previous purchases? Or articles to read based on their 
reading history?

You’ve defined your business problem in machine learning terms and you have data. Now define what defines success. There are different evaluation metrics for 
classification, regression and recommendation problems. Which one you choose will depend on your goal.

For this project to be successful, the model needs to be over 95% accurate at whether someone is at fault or not at fault.

A 95% accurate model may sound pretty good for predicting who’s at fault in an insurance claim. But for predicting heart disease, you’ll likely want better results.

Other things you should take into consideration for classification problems.

False negatives — Model predicts negative, actually positive. In some cases, like email spam prediction, false negatives aren’t too much to worry about. 
But if a self-driving cars computer vision system predicts no pedestrian when there was one, this is not good.
False positives — Model predicts positive, actually negative. Predicting someone has heart disease when they don’t, might seem okay. Better to be safe right? 
Not if it negatively affects the person’s lifestyle or sets them on a treatment plan they don’t need.
True negatives — Model predicts negative, actually negative. This is good.
True positives — Model predicts positive, actually positive. This is good.
Precision — What proportion of positive predictions were actually correct? A model that produces no false positives has a precision of 1.0.
Recall — What proportion of actual positives were predicted correctly? A model that produces no false negatives has a recall of 1.0.
F1 score — A combination of precision and recall. The closer to 1.0, the better.

For regression problems (where you want to predict a number), you’ll want to minimise the difference between what your model predicts and what the actual value is. 
If you’re trying to predict the price a house will sell for, you’ll want your model to get as close as possible to the actual price. To do this, use MAE or RMSE.

Mean absolute error (MAE) — The average difference between your model's predictions and the actual numbers.
Root mean square error (RMSE) — The square root of the average of squared differences between your model's predictions and the actual numbers.
Use RMSE if you want large errors to be more significant. Such as, predicting a house to be sold at $300,000 instead of $200,000 and being off by $100,000 is more 
than twice as bad as being off by $50,000. Or MAE if being off by $100,000 is twice as bad as being off by $50,000.

Recommendation problems are harder to test in experimentation. One way to do so is to take a portion of your data and hide it away. When your model is built, 
use it to predict recommendations for the hidden data and see how it lines up.

Let’s say you’re trying to recommend customers products on your online store. You have historical purchase data from 2010–2019. You could build a model on the 
2010–2018 data and then use it to predict 2019 purchases. Then it becomes a classification problem because you’re trying to classify whether or not someone is 
likely to buy an item.
Receiver operating characteristic (ROC) curve & Area under the curve (AUC) — The ROC curve is a plot comparing true positive and false positive rate. 
The AUC metric is the area under the ROC curve. A model whose predictions are 100% wrong has an AUC of 0.0, one whose predictions are 100% right has an AUC of 1.0.
